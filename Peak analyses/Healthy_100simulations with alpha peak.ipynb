{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heard-chassis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab nbagg\n",
    "from tvb.simulator.lab import *\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from tvb.simulator.lab import *\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy \n",
    "import scipy.fftpack\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy \n",
    "import scipy.fftpack\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "from fooof import FOOOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "generic-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sapphire-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#depressed brain \n",
    "Q_health = np.repeat(1, 76)\n",
    "oscilator = models.WilsonCowan(Q = Q_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "engaged-business",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  File 'hemispheres' not found in ZIP.\n"
     ]
    }
   ],
   "source": [
    "white_matter = connectivity.Connectivity.from_file()\n",
    "white_matter.speed = numpy.array([3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thorough-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_matter_coupling = coupling.Linear(a=numpy.array([0.0039]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prepared-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise some Monitors with period in physical time\n",
    "mon_raw = monitors.Raw(period = 0.9765625)\n",
    "mon_tavg = monitors.TemporalAverage(period = 0.9765625)\n",
    "\n",
    "#Bundle them\n",
    "what_to_watch = (mon_raw, mon_tavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polar-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important variables of dataset\n",
    "sample_period = 0.0009765625 #seconds         \n",
    "sf = 1/sample_period #sampling frequency \n",
    "sample_rate = 1024\n",
    "\n",
    "#sns.set(font_scale=1.2)\n",
    "dt = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "meaningful-selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['areas', 'centres', 'cortical', 'hemispheres', 'orientations', 'region_labels', 'tract_lengths', 'weights']>\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Wilson Cowan/DATA\")\n",
    "#import connectivity file to know which region corresponds to which index in the matrices\n",
    "filename = \"Connectivity.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # Get the data\n",
    "    regions_list = list(f['region_labels'])\n",
    "\n",
    "regions = np.array(regions_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "other-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powercalc(data, low, high, sf, win):\n",
    "    freqs, psd = signal.welch(data, sf, nperseg=win)\n",
    "    freq_res = freqs[1] - freqs[0]\n",
    "    total_power = simps(psd, dx=freq_res)\n",
    "    idx= np.logical_and(freqs >= low, freqs <= high)\n",
    "    power = simps(psd[idx], dx=freq_res)\n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "given-uniform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "check1\n",
      "1024.0\n",
      "2560\n",
      "(2560, 76)\n",
      "check2\n",
      "[[10.55769332  0.97024553  1.        ]]\n",
      "2\n",
      "check1\n",
      "check2\n",
      "[[10.55769332  0.97024553  1.        ]]\n",
      "3\n",
      "check1\n",
      "check2\n",
      "[[10.55769332  0.97024553  1.        ]]\n",
      "4\n",
      "check1\n",
      "check2\n",
      "[[9.761118   0.54484803 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#loop  start om 9u56\n",
    "mydir = \"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Datasets/All_freqs/Peak\"\n",
    "\n",
    "\n",
    "\n",
    "peak_right = {}\n",
    "peak_left = {}\n",
    "\n",
    "win = 4 * sf\n",
    "sf = 1024\n",
    "\n",
    "freq_range = [8,12] \n",
    "\n",
    "indices = [7,  13, 15, 16, 17,18, 19, 20, 21, 30, 31, 33,35, 36, 45, 51, 53, 54, 55, 56, 57, 58, 59, 68, 69, 71 , 73,74]\n",
    "NS_arr = np.arange(0,26, 0.25)\n",
    "\n",
    "counter = 0\n",
    "loop = 1\n",
    "\n",
    "nsubs = 5 #101\n",
    "\n",
    "for i in range(nsubs): \n",
    "    if i == 0:\n",
    "        pass \n",
    "    else:\n",
    "        value = 10**-6 #noise dispertion\n",
    "        NS = NS_arr[i] #changing noise seed\n",
    "        print(loop)\n",
    "        \n",
    "        #create simulator \n",
    "        sim = simulator.Simulator(model = oscilator, connectivity = white_matter,\n",
    "                          coupling = white_matter_coupling, \n",
    "                          integrator = integrators.EulerStochastic(dt=0.01220703125, noise=noise.Additive(noise_seed = int(NS), nsig=numpy.array([value]))),\n",
    "                        monitors =  what_to_watch)\n",
    "\n",
    "        sim.configure()\n",
    "\n",
    "        print(\"check1\")\n",
    "        \n",
    "        #Perform the simulation\n",
    "        tavg_data = []\n",
    "        tavg_time = []\n",
    "\n",
    "        for raw, tavg in sim(simulation_length=2500):\n",
    "    \n",
    "            if not tavg is None:\n",
    "                tavg_time.append(tavg[0])\n",
    "                tavg_data.append(tavg[1])\n",
    "    \n",
    "        #Make the lists numpy.arrays for easier use.\n",
    "        RAW = numpy.array(tavg_data)\n",
    "        RAW_real = RAW[:, 0, :, 0]\n",
    "        \n",
    "        if loop == 1:\n",
    "            sf = len(RAW_real)/2.5 #calculate sampling frequency\n",
    "            print(sf)\n",
    "            print(len(tavg_time))\n",
    "            print(shape(RAW_real))\n",
    "        \n",
    "        print(\"check2\")\n",
    "        #delete the first 500ms\n",
    "        list_deleterows = [*range(0,500,1)]\n",
    "        RAW_real = np.delete(RAW_real, list_deleterows, 0)\n",
    "        tavg_time =  np.delete(tavg_time, list_deleterows, 0)\n",
    "        \n",
    "        #save power spectrum of left DLPFC\n",
    "        leftDLPFC = RAW_real[:,56]\n",
    "        \n",
    "        freqs_left, psd_left = signal.welch(leftDLPFC, sf, nperseg = win)\n",
    "        \n",
    "        fm = FOOOF(peak_width_limits=[1, 8])\n",
    "        fm.fit(freqs_left, psd_left, freq_range)\n",
    "        peaks_left = fm.get_params('peak_params')\n",
    "        peak_left[\"data\" + str(i)] = peaks_left[0][0]\n",
    "        \n",
    "        print(peaks_left)\n",
    "        \n",
    "        #save power spectrum of rigth DLPFC\n",
    "        rightDLPFC = RAW_real[:,18]\n",
    "        \n",
    "        freqs_right, psd_right = signal.welch(rightDLPFC, sf, nperseg = win)\n",
    "        \n",
    "        fm = FOOOF(peak_width_limits=[1, 8])\n",
    "        fm.fit(freqs_right, psd_right, freq_range)\n",
    "        peaks_right = fm.get_params('peak_params')\n",
    "        peak_right[\"data\" + str(i)] = peaks_right[0][0]\n",
    "\n",
    "\n",
    "                \n",
    "        loop = loop +1\n",
    "    \n",
    "\n",
    "\n",
    "#make dataset containing all 100 left DLPFC time series \n",
    "namelist6 = []\n",
    "for i in range(nsubs): #range(101):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        name6 = peak_left[\"data\"+str(i)] \n",
    "        namelist6.append(name6)\n",
    "\n",
    "nametup6 = tuple(namelist6)\n",
    "leftpeaks = np.column_stack(nametup6)\n",
    "\n",
    "#make dataset containing all 100 left DLPFC time series \n",
    "namelist6 = []\n",
    "for i in range(nsubs): #range(101):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        name6 = peak_right[\"data\"+str(i)] \n",
    "        namelist6.append(name6)\n",
    "\n",
    "nametup6 = tuple(namelist6)\n",
    "rightpeaks = np.column_stack(nametup6)\n",
    "\n",
    "\n",
    "\n",
    "file_name = mydir + \"/health_alpha_left_peaks.h5\"\n",
    "h5f = h5py.File(file_name, 'w')\n",
    "h5f.create_dataset('data', data=leftpeaks)\n",
    "h5f.close()\n",
    "\n",
    "file_name = mydir + \"/health_alpha_right_peaks.h5\"\n",
    "h5f = h5py.File(file_name, 'w')\n",
    "h5f.create_dataset('data', data=rightpeaks)\n",
    "h5f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-security",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "thesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
