{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fancy-bradley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "single-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb.simulator.lab import *\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy \n",
    "import scipy.fftpack\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy \n",
    "import scipy.fftpack\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "from fooof import FOOOF\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radical-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Wilson Cowan/DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surprising-russell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['areas', 'centres', 'cortical', 'hemispheres', 'orientations', 'region_labels', 'tract_lengths', 'weights']>\n"
     ]
    }
   ],
   "source": [
    "#import connectivity file to know which region corresponds to which index in the matrices\n",
    "filename = \"Connectivity.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # Get the data\n",
    "    regions_list = list(f['region_labels'])\n",
    "\n",
    "regions = np.array(regions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "peaceful-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import timeseries healthy: alpha power\n",
    "mydir = \"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Datasets/All_freqs\"\n",
    "    \n",
    "filename = mydir + \"/Time_Health.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    healthtime = f[\"time\"]\n",
    "    healthtime = np.array(healthtime)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_overall.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_all = f[\"data\"]\n",
    "    alpha_all = np.array(alpha_all)\n",
    "\n",
    "filename = mydir + \"/power_alpha_lDLPFC.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_left = f[\"data\"]\n",
    "    alpha_left = np.array(alpha_left)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_rDLPFC.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_right = f[\"data\"]\n",
    "    alpha_right = np.array(alpha_right)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_overall_depr.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_all_dep = f[\"data\"]\n",
    "    dep_all = np.array(alpha_all_dep)\n",
    "    \n",
    "\n",
    "filename = mydir + \"/power_alpha_lDLPFC_depr.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_left_depr = f[\"data\"]\n",
    "    alpha_left_depr = np.array(alpha_left_depr)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_rDLPFC_depr.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_right_depr = f[\"data\"]\n",
    "    alpha_right_depr = np.array(alpha_right_depr)\n",
    "    \n",
    "    \n",
    "\n",
    "filename = mydir + \"/power_alpha_overall_HF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_all_HF = f[\"data\"]\n",
    "    HF_all = np.array(alpha_all_HF)\n",
    "    \n",
    "\n",
    "filename = mydir + \"/power_alpha_lDLPFC_HF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_left_HF = f[\"data\"]\n",
    "    alpha_left_HF = np.array(alpha_left_HF)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_rDLPFC_HF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_right_HF = f[\"data\"]\n",
    "    alpha_right_HF = np.array(alpha_right_HF)\n",
    "\n",
    "filename = mydir + \"/power_alpha_overall_LF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_all_LF = f[\"data\"]\n",
    "    LF_all = np.array(alpha_all_LF)\n",
    "    \n",
    "\n",
    "filename = mydir + \"/power_alpha_lDLPFC_LF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_left_LF = f[\"data\"]\n",
    "    alpha_left_LF = np.array(alpha_left_HF)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_rDLPFC_LF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_right_LF = f[\"data\"]\n",
    "    alpha_right_LF = np.array(alpha_right_HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "violent-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "def EFsize(c0, c1):\n",
    "    d = (mean(c0) - mean(c1)) / (sqrt((statistics.stdev(c0) ** 2 + statistics.stdev(c1) ** 2) / 2))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "broad-repair",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert type 'ndarray' to numerator/denominator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-75594bcbaaa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mmeans_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_left_HF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mmeans_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_left_LF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmeans_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mmeans_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_left_depr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mmeans_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_left_HF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documenten\\TVB_Windows_2.2\\TVB_Distribution\\tvb_data\\Lib\\statistics.py\u001b[0m in \u001b[0;36mstdev\u001b[1;34m(data, xbar)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \"\"\"\n\u001b[1;32m--> 649\u001b[1;33m     \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documenten\\TVB_Windows_2.2\\TVB_Distribution\\tvb_data\\Lib\\statistics.py\u001b[0m in \u001b[0;36mvariance\u001b[1;34m(data, xbar)\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variance requires at least two data points'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m     \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documenten\\TVB_Windows_2.2\\TVB_Distribution\\tvb_data\\Lib\\statistics.py\u001b[0m in \u001b[0;36m_ss\u001b[1;34m(data, c)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m     \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[1;31m# The following sum should mathematically equal zero, but due to rounding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documenten\\TVB_Windows_2.2\\TVB_Distribution\\tvb_data\\Lib\\statistics.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean requires at least one data point'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m     \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documenten\\TVB_Windows_2.2\\TVB_Distribution\\tvb_data\\Lib\\statistics.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(data, start)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_coerce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# or raise TypeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_exact_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mpartials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartials_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documenten\\TVB_Windows_2.2\\TVB_Distribution\\tvb_data\\Lib\\statistics.py\u001b[0m in \u001b[0;36m_exact_ratio\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"can't convert type '{}' to numerator/denominator\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert type 'ndarray' to numerator/denominator"
     ]
    }
   ],
   "source": [
    "power_arr = numpy.zeros(shape = (6,5))\n",
    "ef_arr = numpy.zeros(shape = (6,5))\n",
    "means_left = numpy.zeros(shape = (4,2))\n",
    "\n",
    "#alpha over left DLPFC\n",
    "power_arr[0] = stats.ttest_ind(alpha_left, alpha_left_depr).pvalue #depr vs healthy \n",
    "power_arr[1] = stats.ttest_ind(alpha_left_LF, alpha_left).pvalue #LF vs healthy \n",
    "power_arr[2] = stats.ttest_ind(alpha_left_HF, alpha_left).pvalue #HF vs healthy \n",
    "power_arr[3] = stats.ttest_ind(alpha_left_LF, alpha_left_depr).pvalue #depr vs LF\n",
    "power_arr[4] = stats.ttest_ind(alpha_left_HF, alpha_left_depr).pvalue #depr vs HF\n",
    "power_arr[5] = stats.ttest_ind(alpha_left_HF,alpha_left_LF).pvalue #HF vs LF\n",
    "\n",
    "for i in range(5):\n",
    "    ef_arr[0,i] = EFsize(alpha_left[i], alpha_left_depr[i]) #depr vs healthy \n",
    "    ef_arr[1,i] = EFsize(alpha_left_LF[i], alpha_left[i]) #LF vs healthy \n",
    "    ef_arr[2,i] = EFsize(alpha_left_HF[i], alpha_left[i])#HF vs healthy \n",
    "    ef_arr[3,i] = EFsize(alpha_left_LF[i], alpha_left_depr[i]) #depr vs LF\n",
    "    ef_arr[4,i] = EFsize(alpha_left_HF[i], alpha_left_depr[i]) #depr vs HF\n",
    "    ef_arr[5,i] = EFsize(alpha_left_HF[i],alpha_left_LF[i]) #HF vs LF\n",
    "    \n",
    "means_left[0,0] = mean(alpha_left)\n",
    "means_left[1,0] = mean(alpha_left_depr)\n",
    "means_left[2,0] = mean(alpha_left_HF)\n",
    "means_left[3,0] = mean(alpha_left_LF)\n",
    "means_left[0,1] = stdev(alpha_left)\n",
    "means_left[1,1] = stdev(alpha_left_depr)\n",
    "means_left[2,1] = stdev(alpha_left_HF)\n",
    "means_left[3,1] = stdev(alpha_left_LF)\n",
    "\n",
    "\n",
    "\n",
    "new_column = [\"Depr_health\", \"LF_health\",\"HF_health\",\"depr_LF\",\"depr_HF\",\"HF_LF\"]\n",
    "tuple = (power_arr, ef_arr, new_column)\n",
    "power_arr_tot = np.column_stack(tuple)\n",
    "\n",
    "file_name = mydir + \"/Alpha_leftDLPFC.csv\"\n",
    "outcome = pd.DataFrame.from_records(power_arr_tot)\n",
    "outcome.columns = [\"p 8_9\", \"p 9_10\", \"p 10_11\", \"p 11_12\", \"p 8_12\",\"ef 8_9\", \"ef 9_10\", \"ef 10_11\", \"ef 11_12\", \"ef 8_12\", \"comparison\"]\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "suspended-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.71369649e-07 1.71369649e-07]\n",
      " [7.21824016e-08 7.21824016e-08]\n",
      " [1.88531545e-05 1.88531545e-05]\n",
      " [1.88531545e-05 1.88531545e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(means_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "metallic-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_arr = numpy.zeros(shape = (6,5))\n",
    "ef_arr = numpy.zeros(shape = (6,5))\n",
    "\n",
    "means_all = numpy.zeros(shape = (4,2))\n",
    "\n",
    "#alpha over all regions\n",
    "power_arr[0] = stats.ttest_ind(alpha_all, dep_all).pvalue #depr vs healthy \n",
    "power_arr[1] = stats.ttest_ind(LF_all, alpha_all).pvalue #LF vs healthy \n",
    "power_arr[2] = stats.ttest_ind(HF_all, alpha_all).pvalue #HF vs healthy \n",
    "power_arr[3] = stats.ttest_ind(LF_all, dep_all).pvalue #depr vs LF\n",
    "power_arr[4] = stats.ttest_ind(HF_all, dep_all).pvalue #depr vs HF\n",
    "power_arr[5] = stats.ttest_ind(HF_all, LF_all).pvalue #HF vs LF\n",
    "\n",
    "for i in range(5):\n",
    "    ef_arr[0,i] = EFsize(alpha_all[i], dep_all[i]) #depr vs healthy \n",
    "    ef_arr[1,i] = EFsize(LF_all[i], alpha_all[i]) #LF vs healthy \n",
    "    ef_arr[2,i] = EFsize(HF_all[i], alpha_all[i])#HF vs healthy \n",
    "    ef_arr[3,i] = EFsize(LF_all[i], dep_all[i]) #depr vs LF\n",
    "    ef_arr[4,i] = EFsize(HF_all[i], dep_all[i]) #depr vs HF\n",
    "    ef_arr[5,i] = EFsize(HF_all[i],LF_all[i]) #HF vs LF\n",
    "    \n",
    "means_all[0,0] = mean(alpha_all)\n",
    "means_all[1,0] = mean(dep_all)\n",
    "means_all[2,0] = mean(HF_all)\n",
    "means_all[3,0] = mean(LF_all)\n",
    "means_all[0,1] = stdev(alpha_all)\n",
    "means_all[1,1] = stdev(dep_all)\n",
    "means_all[2,1] = stdev(HF_all)\n",
    "means_all[3,1] = stdev(LF_all)\n",
    "\n",
    "new_column = [\"Depr_health\", \"LF_health\",\"HF_health\",\"depr_LF\",\"depr_HF\",\"HF_LF\"]\n",
    "tuple = (power_arr, ef_arr, new_column)\n",
    "power_arr_tot = np.column_stack(tuple)\n",
    "\n",
    "file_name = mydir + \"/Alpha_all_regions.csv\"\n",
    "outcome = pd.DataFrame.from_records(power_arr_tot)\n",
    "outcome.columns = [\"p 8_9\", \"p 9_10\", \"p 10_11\", \"p 11_12\", \"p 8_12\",\"ef 8_9\", \"ef 9_10\", \"ef 10_11\", \"ef 11_12\", \"ef 8_12\", \"comparison\"]\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "herbal-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_arr = numpy.zeros(shape = (6,5))\n",
    "ef_arr = numpy.zeros(shape = (6,5))\n",
    "\n",
    "means_right = numpy.zeros(shape = (4,2))\n",
    "\n",
    "#alpha over right DLFPC\n",
    "power_arr[0] = stats.ttest_ind(alpha_right, alpha_right_depr).pvalue #depr vs healthy \n",
    "power_arr[1] = stats.ttest_ind(alpha_right_LF, alpha_right).pvalue #LF vs healthy \n",
    "power_arr[2] = stats.ttest_ind(alpha_right_HF, alpha_right).pvalue #HF vs healthy \n",
    "power_arr[3] = stats.ttest_ind(alpha_right_LF, alpha_right_depr).pvalue #depr vs LF\n",
    "power_arr[4] = stats.ttest_ind(alpha_right_HF, alpha_right_depr).pvalue #depr vs HF\n",
    "power_arr[5] = stats.ttest_ind(alpha_right_HF,alpha_right_LF).pvalue #HF vs LF\n",
    "\n",
    "for i in range(5):\n",
    "    ef_arr[0,i] = EFsize(alpha_right[i], alpha_right_depr[i]) #depr vs healthy \n",
    "    ef_arr[1,i] = EFsize(alpha_right_LF[i], alpha_right[i]) #LF vs healthy \n",
    "    ef_arr[2,i] = EFsize(alpha_right_HF[i], alpha_right[i])#HF vs healthy \n",
    "    ef_arr[3,i] = EFsize(alpha_right_LF[i], alpha_right_depr[i]) #depr vs LF\n",
    "    ef_arr[4,i] = EFsize(alpha_right_HF[i], alpha_right_depr[i]) #depr vs HF\n",
    "    ef_arr[5,i] = EFsize(alpha_right_HF[i],alpha_right_LF[i]) #HF vs LF\n",
    "    \n",
    "\n",
    "means_right[0,0] = mean(alpha_right)\n",
    "means_right[1,0] = mean(alpha_right_depr)\n",
    "means_right[2,0] = mean(alpha_right_HF)\n",
    "means_right[3,0] = mean(alpha_right_LF)\n",
    "means_right[0,1] = stdev(alpha_right)\n",
    "means_right[1,1] = stdev(alpha_right_depr)\n",
    "means_right[2,1] = stdev(alpha_right_HF)\n",
    "means_right[3,1] = stdev(alpha_right_LF)\n",
    "\n",
    "new_column = [\"Depr_health\", \"LF_health\",\"HF_health\",\"depr_LF\",\"depr_HF\",\"HF_LF\"]\n",
    "tuple = (power_arr, ef_arr, new_column)\n",
    "power_arr_tot = np.column_stack(tuple)\n",
    "\n",
    "file_name = mydir + \"/Alpha_rightDLPFC.csv\"\n",
    "outcome = pd.DataFrame.from_records(power_arr_tot)\n",
    "outcome.columns = [\"p 8_9\", \"p 9_10\", \"p 10_11\", \"p 11_12\", \"p 8_12\",\"ef 8_9\", \"ef 9_10\", \"ef 10_11\", \"ef 11_12\", \"ef 8_12\", \"comparison\"]\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "duplicate-rugby",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stdev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-44a6f3276391>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mmeans_as\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHF_as\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mmeans_as\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLF_as\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mmeans_as\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhealth_as\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mmeans_as\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepr_as\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mmeans_as\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstdev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHF_as\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stdev' is not defined"
     ]
    }
   ],
   "source": [
    "power_arr = numpy.zeros(shape = (6,5))\n",
    "ef_arr = numpy.zeros(shape = (6,5))\n",
    "means_as = numpy.zeros(shape = (4,2))\n",
    "\n",
    "#alpha asymmetry values \n",
    "depr_as = alpha_left_depr/alpha_right_depr\n",
    "health_as = alpha_left/alpha_right\n",
    "HF_as = alpha_left_HF/alpha_right_HF\n",
    "LF_as = alpha_left_LF/alpha_right_LF\n",
    "\n",
    "\n",
    "power_arr[0] = stats.ttest_ind(depr_as, health_as).pvalue #depr vs healthy \n",
    "power_arr[1] = stats.ttest_ind(LF_as, health_as).pvalue #LF vs healthy \n",
    "power_arr[2] = stats.ttest_ind(HF_as, health_as).pvalue #HF vs healthy \n",
    "power_arr[3] = stats.ttest_ind(LF_as, depr_as).pvalue #depr vs LF\n",
    "power_arr[4] = stats.ttest_ind(HF_as, depr_as).pvalue #depr vs HF\n",
    "power_arr[5] = stats.ttest_ind(HF_as,LF_as).pvalue #HF vs LF\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    ef_arr[0,i] = EFsize(health_as[i], depr_as[i]) #depr vs healthy \n",
    "    ef_arr[1,i] = EFsize(LF_as[i], health_as[i]) #LF vs healthy \n",
    "    ef_arr[2,i] = EFsize(HF_as[i], health_as[i])#HF vs healthy \n",
    "    ef_arr[3,i] = EFsize(LF_as[i], depr_as[i]) #depr vs LF\n",
    "    ef_arr[4,i] = EFsize(HF_as[i], depr_as[i]) #depr vs HF\n",
    "    ef_arr[5,i] = EFsize(HF_as[i],LF_as[i]) #HF vs LF\n",
    "    \n",
    "\n",
    "means_as[0,0] = mean(health_as)\n",
    "means_as[1,0] = mean(depr_as)\n",
    "means_as[2,0] = mean(HF_as)\n",
    "means_as[3,0] = mean(LF_as)\n",
    "means_as[0,1] = stdev(health_as)\n",
    "means_as[1,1] = stdev(depr_as)\n",
    "means_as[2,1] = stdev(HF_as)\n",
    "means_as[3,1] = stdev(LF_as)\n",
    "\n",
    "new_column = [\"Depr_health\", \"LF_health\",\"HF_health\",\"depr_LF\",\"depr_HF\",\"HF_LF\"]\n",
    "tuple = (power_arr, ef_arr, new_column)\n",
    "power_arr_tot = np.column_stack(tuple)\n",
    "\n",
    "file_name = mydir + \"/Alpha_asymmetry.csv\"\n",
    "outcome = pd.DataFrame.from_records(power_arr_tot)\n",
    "outcome.columns = [\"p 8_9\", \"p 9_10\", \"p 10_11\", \"p 11_12\", \"p 8_12\",\"ef 8_9\", \"ef 9_10\", \"ef 10_11\", \"ef 11_12\", \"ef 8_12\", \"comparison\"]\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-plate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "thesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
