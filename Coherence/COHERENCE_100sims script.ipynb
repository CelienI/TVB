{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab nbagg\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scipy \n",
    "import scipy.fftpack\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy import signal\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Datasets\")\n",
    "mydir = \"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5(filename):\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        df = f['data'][:]\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "filename = mydir + \"/Time_health.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "     t = f['time'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Wilson Cowan/DATA\")\n",
    "#import connectivity file to know which region corresponds to which index in the matrices\n",
    "filename = \"Connectivity.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # Get the data\n",
    "    regions_list = list(f['region_labels'])\n",
    "\n",
    "regions = np.array(regions_list)\n",
    "\n",
    "indices = [*range(0,76 , 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in healthy brains 9u45\n",
    "H_var = {}\n",
    "for i in range(100): #(100):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        filename = mydir + \"/Health_\" + str(i) + \".h5\"\n",
    "        H_var['H_' + str(i)] = load_h5(filename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove first 500ms\n",
    "list_deleterows = [*range(0,46000,1)]\n",
    "\n",
    "for i in H_var:\n",
    "    H_var[i]= np.delete(H_var[i], list_deleterows, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in depressed brains  \n",
    "D_var = {}\n",
    "for i in range(100):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        filename = mydir + \"/Depr_\" + str(i) + \".h5\"\n",
    "        D_var['D_' + str(i)] = load_h5(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in D_var:\n",
    "    D_var[i]= np.delete(D_var[i], list_deleterows, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in stimulated brain: HF \n",
    "HF_var = {}\n",
    "for i in range(40):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        filename = mydir + \"/HF_\" + str(i) + \".h5\"\n",
    "        HF_var['HF_' + str(i)] = load_h5(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in stimulated brain: LF\n",
    "LF_var = {}\n",
    "for i in range(100):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        filename = mydir + \"/LF_\" + str(i) + \".h5\"\n",
    "        LF_var['LF_' + str(i)] = load_h5(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove first 500ms\n",
    "list_deleterows = [*range(0,46000,1)]\n",
    "\n",
    "for i in H_var:\n",
    "    H_var[i]= np.delete(H_var[i], list_deleterows, 0)\n",
    "for i in D_var:\n",
    "    D_var[i]= np.delete(D_var[i], list_deleterows, 0)\n",
    "for i in HF_var:\n",
    "    HF_var[i]= np.delete(HF_var[i], list_deleterows, 0)\n",
    "for i in LF_var:\n",
    "    LF_var[i]= np.delete(LF_var[i], list_deleterows, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_deleterows = [*range(0,46000,1)]\n",
    "t = np.delete(t, list_deleterows, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dimensions\n",
    "print(shape(t))\n",
    "print(shape(H_var['H_1']))\n",
    "print(shape(LF_var['LF_1']))\n",
    "print(shape(D_var['D_1']))\n",
    "print(shape(HF_var['HF_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prefrontal = [17,18, 19, 55, 56, 57]\n",
    "\n",
    "\n",
    "prefr_left = [55, 56, 57],[17,18, 19]\n",
    "temp_left = [38, 39, 68, 69, 71, 72]\n",
    "par_left = [51, 53, 54]\n",
    "occ_left = [73, 74]\n",
    "\n",
    "\n",
    "#frontal – temporal  (Leuchter, Li)\n",
    "# --> PFCcl, PFCdl, PFCdm, PFCm, PFCorb, FEF, PFCvl\n",
    "prefrontal = [7, 17,18, 19, 20, 21, 23, 45, 55, 56, 57, 58, 59,61]\n",
    "#temporal --> TCc, TCi, TCs, A1, A2\n",
    "temporal = [0, 1, 30, 31, 33, 38, 39, 68, 69, 71 ]\n",
    "\n",
    "#frontal – occipital (Leuchter)\n",
    "# --> occipital: V1, V2\n",
    "occipital = [35, 36, 73,74]\n",
    "\n",
    "#frontal – parietal (Leuchter, Li)\n",
    "# parietal --> PCi, PCm, PCs\n",
    "parietal = [ 13, 15, 16, 51, 53, 54]\n",
    "\n",
    "indices = [0, 1,7,  13, 15, 16, 17,18, 19, 20, 21, 23,30, 31, 33,35, 36,38, 39, 45, 51, 53, 54, 55, 56, 57, 58, 59,61, 68, 69, 71 , 73,74]\n",
    "print(len(indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in indices:\n",
    "    for b in indices:\n",
    "        if i == b:\n",
    "            pass\n",
    "        if i < b:\n",
    "            pass\n",
    "        else:\n",
    "            for x in range(40):\n",
    "                count = count + 1\n",
    "print(count) #16240 loops necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important variables of dataset\n",
    "sample_period = 0.0009765625 #seconds         CHECKEN OF DIT JUIST IS\n",
    "sf = 1/sample_period #sampling frequency \n",
    "sample_rate = 1024\n",
    "\n",
    "#sns.set(font_scale=1.2)\n",
    "dt = 0.01\n",
    "t = t #time, defined when loading in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOOP FOR LOW ALPHA BAND: prefrontal- prefrontal ROIs \n",
    "c1 = np.repeat(\"\", 1)\n",
    "c2 = np.repeat(\"\",1)\n",
    "cRest = numpy.zeros(shape=(1,17))\n",
    "sig_array = np.column_stack([c1, c2, cRest])\n",
    "sig_array_tot = np.column_stack([c1, c2, cRest])\n",
    "\n",
    "p_count = 0\n",
    "paircounter = 0\n",
    "\n",
    "indices = [0, 1,7,  13, 15, 16, 17,18, 19, 20, 21, 23,30, 31, 33,35, 36,38, 39, 45, 51, 53, 54, 55, 56, 57, 58, 59,61, 68, 69, 71 , 73,74]\n",
    "\n",
    "for ROI1 in  indices:\n",
    "    for ROI2 in  indices:\n",
    "        if ROI1 == ROI2:\n",
    "            pass\n",
    "        elif ROI1 < ROI2:\n",
    "            pass \n",
    "        \n",
    "        else:\n",
    "            count_h = 0\n",
    "            count_d = 0\n",
    "            count_hf = 0\n",
    "            count_lf = 0\n",
    "            for i in H_var:\n",
    "                #healthy \n",
    "                xh = H_var[i][:, ROI1]\n",
    "                yh = H_var[i][:, ROI2]\n",
    "                cxy_h, f_h = cohere(xh, yh, 256, 1. / dt)\n",
    "                cxy_low_h, f_low_h = cxy_h[21:26], f_h[21:26]\n",
    "                \n",
    "                if count_h == 0:\n",
    "                    health_low = cxy_low_h\n",
    "                else:\n",
    "                    health_low = np.append(health_low, cxy_low_h)\n",
    "                count_h = count_h + 1\n",
    "                \n",
    "            for i in D_var:\n",
    "                #depressed \n",
    "                xd = D_var[i][:, ROI1]\n",
    "                yd = D_var[i][:, ROI2]\n",
    "                cxy_d, f_d = cohere(xd, yd, 256, 1. / dt)\n",
    "                cxy_low_d, f_low_d = cxy_d[21:26], f_d[21:26]\n",
    "                \n",
    "                if count_d == 0:\n",
    "                    dep_low = cxy_low_d\n",
    "                else:\n",
    "                    dep_low = np.append(dep_low, cxy_low_d)\n",
    "                    \n",
    "                count_d = count_d + 1\n",
    "            \n",
    "            for i in HF_var:\n",
    "                #HF stimulation \n",
    "                xhf = HF_var[i][:, ROI1]\n",
    "                yhf = HF_var[i][:, ROI2]\n",
    "                cxy_hf, f_hf = cohere(xhf, yhf, 256, 1. / dt)\n",
    "                cxy_low_hf, f_low_hf = cxy_hf[21:26], f_hf[21:26]\n",
    "                \n",
    "                if count_hf == 0:\n",
    "                    hf_low = cxy_low_hf\n",
    "                else:\n",
    "                    hf_low = np.append(hf_low, cxy_low_hf)\n",
    "                count_hf = count_hf + 1\n",
    "            \n",
    "            for i in LF_var:\n",
    "                #LF stimulation \n",
    "                xlf = LF_var[i][:, ROI1]\n",
    "                ylf = LF_var[i][:, ROI2]\n",
    "                cxy_lf, f_lf = cohere(xlf, ylf, 256, 1. / dt)\n",
    "                cxy_low_lf, f_low_lf = cxy_lf[21:26], f_lf[21:26]\n",
    "                \n",
    "                if count_lf == 0:\n",
    "                    lf_low = cxy_low_lf\n",
    "                else:\n",
    "                    lf_low = np.append(lf_low, cxy_low_lf)\n",
    "                    \n",
    "                count_lf = count_lf + 1\n",
    "                \n",
    "            p_h_d = stats.ttest_ind(dep_low,health_low).pvalue #healthy vs depressed\n",
    "            p_h_hf = stats.ttest_ind(hf_low,health_low).pvalue #healthy vs HF\n",
    "            p_h_lf = stats.ttest_ind(lf_low,health_low).pvalue #healthy vs LF\n",
    "            p_d_hf = stats.ttest_ind(dep_low,hf_low).pvalue #depr vs HF\n",
    "            p_d_lf = stats.ttest_ind(dep_low,lf_low).pvalue #depr vs LF\n",
    "            \n",
    "            paircounter = paircounter + 1\n",
    "            print(paircounter)\n",
    "            print(p_h_d)\n",
    "            if p_h_d <= 0.05 or p_h_hf <= 0.05 or p_h_lf <= 0.05 or p_d_hf <= 0.05 or p_d_lf <= 0.05:\n",
    "                print(\"yes\")\n",
    "                sig_array[0][0] = str(regions[ROI1])\n",
    "                sig_array[0][1] = str(regions[ROI2])\n",
    "                sig_array[0][2] = mean(dep_low)\n",
    "                sig_array[0][3] = mean(health_low)\n",
    "                sig_array[0][4] = mean(hf_low)\n",
    "                sig_array[0][5] = mean(lf_low)\n",
    "                sig_array[0][6] = std(dep_low)\n",
    "                sig_array[0][7] = std(health_low)\n",
    "                sig_array[0][8] = std(hf_low)\n",
    "                sig_array[0][9] = std(lf_low)\n",
    "                sig_array[0][10] = p_h_d\n",
    "                sig_array[0][11] = p_h_hf\n",
    "                sig_array[0][12] = p_h_lf\n",
    "                sig_array[0][13] = p_d_hf\n",
    "                sig_array[0][14] = p_d_lf\n",
    "                sig_array[0][15] = ROI1\n",
    "                sig_array[0][16] = ROI2\n",
    "                sig_array[0][17] = min(f_low_h)\n",
    "                sig_array[0][18] = max(f_low_h)\n",
    "                \n",
    "                if p_count == 0:\n",
    "                    sig_array_tot[0][0] = str(regions[ROI1])\n",
    "                    sig_array_tot[0][1] = str(regions[ROI2])\n",
    "                    sig_array_tot[0][2] = mean(dep_low)\n",
    "                    sig_array_tot[0][3] = mean(health_low)\n",
    "                    sig_array_tot[0][4] = mean(hf_low)\n",
    "                    sig_array_tot[0][5] = mean(lf_low)\n",
    "                    sig_array_tot[0][6] = std(dep_low)\n",
    "                    sig_array_tot[0][7] = std(health_low)\n",
    "                    sig_array_tot[0][8] = std(hf_low)\n",
    "                    sig_array_tot[0][9] = std(lf_low)\n",
    "                    sig_array_tot[0][10] = p_h_d\n",
    "                    sig_array_tot[0][11] = p_h_hf\n",
    "                    sig_array_tot[0][12] = p_h_lf\n",
    "                    sig_array_tot[0][13] = p_d_hf\n",
    "                    sig_array_tot[0][14] = p_d_lf\n",
    "                    sig_array_tot[0][15] = ROI1\n",
    "                    sig_array_tot[0][16] = ROI2\n",
    "                    sig_array_tot[0][17] = min(f_low_h)\n",
    "                    sig_array_tot[0][18] = max(f_low_h)\n",
    "                    \n",
    "                else:\n",
    "                    sig_tuple = (sig_array_tot, sig_array)\n",
    "                    sig_array_tot = np.vstack(sig_tuple)\n",
    "                \n",
    "                p_count = p_count + 1\n",
    "\n",
    "\n",
    "file_name1 = mydir + \"/coherence_low_selectedROIs.csv\"\n",
    "outcome1 = pd.DataFrame.from_records(sig_array_tot)\n",
    "outcome1.columns = [\"ROI1\", \"ROI2\", \"mean_coh_d\", \"mean_coh_h\", \"mean_coh_hf\", \"mean_coh_lf\", \"sd_coh_d\", \"sd_coh_h\",\n",
    "                    \"sd_coh_hf\",\"sd_coh_lf\",\"p-H_D\", \"p-H-HF\",\"p-H_LF\",\"p-D_HF\",\"p-D_LF\" ,\"ROI1_nr\",\"ROI2_nr\", \"f_min\", \"f_max\"]\n",
    "outcome1.to_csv(path_or_buf = file_name1, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9u1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "thesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
