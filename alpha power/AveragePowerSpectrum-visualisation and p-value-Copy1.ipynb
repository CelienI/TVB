{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cloudy-initial",
   "metadata": {},
   "source": [
    "Script to compute p-values on differences in alpha power in specific regions for all brain types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-reliance",
   "metadata": {},
   "source": [
    "Previous scripts (to compute alpha power across 100simulations):\n",
    "    HF_100simluations with PSD\n",
    "    LF_100simluations with PSD\n",
    "    depr_100simluations with PSD\n",
    "    health_100simluations with PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "single-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb.simulator.lab import *\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy \n",
    "import scipy.fftpack\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy \n",
    "import scipy.fftpack\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "from fooof import FOOOF\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radical-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Wilson Cowan/DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surprising-russell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['areas', 'centres', 'cortical', 'hemispheres', 'orientations', 'region_labels', 'tract_lengths', 'weights']>\n"
     ]
    }
   ],
   "source": [
    "#import connectivity file to know which region corresponds to which index in the matrices\n",
    "filename = \"Connectivity.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # Get the data\n",
    "    regions_list = list(f['region_labels'])\n",
    "\n",
    "regions = np.array(regions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "peaceful-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import timeseries healthy: alpha power\n",
    "mydir = \"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Datasets/All_freqs\"\n",
    "    \n",
    "filename = mydir + \"/Time_Health.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    healthtime = f[\"time\"]\n",
    "    healthtime = np.array(healthtime)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_overall.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_all = f[\"data\"]\n",
    "    alpha_all = np.array(alpha_all)\n",
    "\n",
    "filename = mydir + \"/power_alpha_lDLPFC.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_left = f[\"data\"]\n",
    "    alpha_left = np.array(alpha_left)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_rDLPFC.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_right = f[\"data\"]\n",
    "    alpha_right = np.array(alpha_right)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_overall_depr.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_all_dep = f[\"data\"]\n",
    "    dep_all = np.array(alpha_all_dep)\n",
    "    \n",
    "\n",
    "filename = mydir + \"/power_alpha_lDLPFC_depr.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_left_depr = f[\"data\"]\n",
    "    alpha_left_depr = np.array(alpha_left_depr)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_rDLPFC_depr.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_right_depr = f[\"data\"]\n",
    "    alpha_right_depr = np.array(alpha_right_depr)\n",
    "    \n",
    "    \n",
    "\n",
    "filename = mydir + \"/power_alpha_overall_HF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_all_HF = f[\"data\"]\n",
    "    HF_all = np.array(alpha_all_HF)\n",
    "    \n",
    "\n",
    "filename = mydir + \"/power_alpha_lDLPFC_HF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_left_HF = f[\"data\"]\n",
    "    alpha_left_HF = np.array(alpha_left_HF)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_rDLPFC_HF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_right_HF = f[\"data\"]\n",
    "    alpha_right_HF = np.array(alpha_right_HF)\n",
    "\n",
    "filename = mydir + \"/power_alpha_overall_LF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_all_LF = f[\"data\"]\n",
    "    LF_all = np.array(alpha_all_LF)\n",
    "    \n",
    "\n",
    "filename = mydir + \"/power_alpha_lDLPFC_LF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_left_LF = f[\"data\"]\n",
    "    alpha_left_LF = np.array(alpha_left_HF)\n",
    "    \n",
    "filename = mydir + \"/power_alpha_rDLPFC_LF.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    alpha_right_LF = f[\"data\"]\n",
    "    alpha_right_LF = np.array(alpha_right_HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "violent-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "\n",
    "statsx = importr('stats')\n",
    "\n",
    "def EFsize(c0, c1):\n",
    "    d = (mean(c0) - mean(c1)) / (sqrt((statistics.stdev(c0) ** 2 + statistics.stdev(c1) ** 2) / 2))\n",
    "    return d\n",
    "\n",
    "mydir = \"C:/Users/celie/OneDrive - ugentbe/NOG NODIG/2de master/Masterproef/Datasets/All_freqs/alfapower\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "addressed-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "#left frontal alfa \n",
    "\n",
    "for i in range(5):\n",
    "    #first: compare all lowest frequencies \n",
    "    #4 means, 4 sd's, 6p-values, 6EFs, 6 corrected p-values\n",
    "    \n",
    "    health = alpha_left[:,i]\n",
    "    depr = alpha_left_depr[:,i]\n",
    "    LF = alpha_left_LF[:,i]\n",
    "    HF = alpha_left_HF[:,i]\n",
    "\n",
    "    array = numpy.zeros(shape = (1, 20))\n",
    "\n",
    "    array[0][0] = mean(health)\n",
    "    array[0][1] = mean(depr)\n",
    "    array[0][2] = mean(LF)\n",
    "    array[0][3] = mean(HF)\n",
    "    array[0][4] = np.std(health)\n",
    "    array[0][5] = np.std(depr)\n",
    "    array[0][6] = np.std(LF)\n",
    "    array[0][7] = np.std(HF)\n",
    "    array[0][8] = stats.ttest_ind(health, depr).pvalue\n",
    "    array[0][9] = stats.ttest_ind(health, LF).pvalue\n",
    "    array[0][10] = stats.ttest_ind(health, HF).pvalue\n",
    "    array[0][11] = stats.ttest_ind(LF, depr).pvalue\n",
    "    array[0][12] = stats.ttest_ind(HF, depr).pvalue\n",
    "    array[0][13] = stats.ttest_ind(HF, LF).pvalue\n",
    "    array[0][14] = EFsize(health, depr)\n",
    "    array[0][15] = EFsize(health, LF)\n",
    "    array[0][16] = EFsize(health, HF)\n",
    "    array[0][17] = EFsize(LF, depr)\n",
    "    array[0][18] = EFsize(HF, depr)\n",
    "    array[0][19] = EFsize(HF, LF)\n",
    "\n",
    "    #make new array with adjusted p-values!\n",
    "    if i == 0:\n",
    "        array0 = array\n",
    "    elif i ==1:\n",
    "        array1 = array\n",
    "    elif i == 2:\n",
    "        array2 = array\n",
    "    elif i == 3:\n",
    "        array3 = array\n",
    "    else:\n",
    "        array4 = array\n",
    "\n",
    "tuple = (array0, array1, array2, array3, array4)\n",
    "total = np.vstack(tuple)\n",
    "\n",
    "\n",
    "\n",
    "parray = total[:, [8,9,10,11,12,13]]\n",
    "\n",
    "padj = np.copy(parray)\n",
    "\n",
    "padj[:,0] = statsx.p_adjust(FloatVector(parray[:,0]), method = 'holm')\n",
    "padj[:,1] = statsx.p_adjust(FloatVector(parray[:,1]), method = 'holm')\n",
    "padj[:,2] = statsx.p_adjust(FloatVector(parray[:,2]), method = 'holm')\n",
    "padj[:,3] = statsx.p_adjust(FloatVector(parray[:,3]), method = 'holm')\n",
    "padj[:,4] = statsx.p_adjust(FloatVector(parray[:,4]), method = 'holm')\n",
    "padj[:,5] = statsx.p_adjust(FloatVector(parray[:,5]), method = 'holm')\n",
    "\n",
    "tuplex = (total, padj)\n",
    "total_adj = np.column_stack(tuplex)\n",
    "\n",
    "file_name = mydir + \"/left frontal alfa p-values.csv\"\n",
    "outcome = pd.DataFrame.from_records(total_adj)\n",
    "outcome.columns = [\"mean health\",\"mean depr\",\"meanLF\", \"meanHF\", \"std health\",\"std depr\",\"std LF\",\"std HF\",\"p H_D\",\"p H_LF\",\n",
    "                  \"p H_HF\",\"p LF_depr\",\"p HF_depr\",\"p HF_LF\",\"ES H_HF\", \"ES H_LF\",\"ES H_HF\",\"ES LF_depr\",\"ES HF_depr\",\"ES HF_LF\",\n",
    "                  \"p adj H_depr\", \"p adj H_LF\", \"p adj H_HF\",\"p adj LF_depr\", \"p adj HF_depr\", \"p adj HF_LF\"]\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "treated-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#right frontal alfa \n",
    "\n",
    "for i in range(5):\n",
    "    #first: compare all lowest frequencies \n",
    "    #4 means, 4 sd's, 6p-values, 6EFs, 6 corrected p-values\n",
    "    \n",
    "    health = alpha_right[:,i]\n",
    "    depr = alpha_right_depr[:,i]\n",
    "    LF = alpha_right_LF[:,i]\n",
    "    HF = alpha_right_HF[:,i]\n",
    "\n",
    "    array = numpy.zeros(shape = (1, 20))\n",
    "\n",
    "    array[0][0] = mean(health)\n",
    "    array[0][1] = mean(depr)\n",
    "    array[0][2] = mean(LF)\n",
    "    array[0][3] = mean(HF)\n",
    "    array[0][4] = np.std(health)\n",
    "    array[0][5] = np.std(depr)\n",
    "    array[0][6] = np.std(LF)\n",
    "    array[0][7] = np.std(HF)\n",
    "    array[0][8] = stats.ttest_ind(health, depr).pvalue\n",
    "    array[0][9] = stats.ttest_ind(health, LF).pvalue\n",
    "    array[0][10] = stats.ttest_ind(health, HF).pvalue\n",
    "    array[0][11] = stats.ttest_ind(LF, depr).pvalue\n",
    "    array[0][12] = stats.ttest_ind(HF, depr).pvalue\n",
    "    array[0][13] = stats.ttest_ind(HF, LF).pvalue\n",
    "    array[0][14] = EFsize(health, depr)\n",
    "    array[0][15] = EFsize(health, LF)\n",
    "    array[0][16] = EFsize(health, HF)\n",
    "    array[0][17] = EFsize(LF, depr)\n",
    "    array[0][18] = EFsize(HF, depr)\n",
    "    array[0][19] = EFsize(HF, LF)\n",
    "\n",
    "    #make new array with adjusted p-values!\n",
    "    if i == 0:\n",
    "        array0 = array\n",
    "    elif i ==1:\n",
    "        array1 = array\n",
    "    elif i == 2:\n",
    "        array2 = array\n",
    "    elif i == 3:\n",
    "        array3 = array\n",
    "    else:\n",
    "        array4 = array\n",
    "\n",
    "tuple = (array0, array1, array2, array3, array4)\n",
    "total = np.vstack(tuple)\n",
    "\n",
    "parray = total[:, [8,9,10,11,12,13]]\n",
    "\n",
    "padj = np.copy(parray)\n",
    "\n",
    "padj[:,0] = statsx.p_adjust(FloatVector(parray[:,0]), method = 'holm')\n",
    "padj[:,1] = statsx.p_adjust(FloatVector(parray[:,1]), method = 'holm')\n",
    "padj[:,2] = statsx.p_adjust(FloatVector(parray[:,2]), method = 'holm')\n",
    "padj[:,3] = statsx.p_adjust(FloatVector(parray[:,3]), method = 'holm')\n",
    "padj[:,4] = statsx.p_adjust(FloatVector(parray[:,4]), method = 'holm')\n",
    "padj[:,5] = statsx.p_adjust(FloatVector(parray[:,5]), method = 'holm')\n",
    "\n",
    "tuplex = (total, padj)\n",
    "total_adj = np.column_stack(tuplex)\n",
    "\n",
    "file_name = mydir + \"/right frontal alfa p-values.csv\"\n",
    "outcome = pd.DataFrame.from_records(total_adj)\n",
    "outcome.columns = [\"mean health\",\"mean depr\",\"meanLF\", \"meanHF\", \"std health\",\"std depr\",\"std LF\",\"std HF\",\"p H_D\",\"p H_LF\",\n",
    "                  \"p H_HF\",\"p LF_depr\",\"p HF_depr\",\"p HF_LF\",\"ES H_HF\", \"ES H_LF\",\"ES H_HF\",\"ES LF_depr\",\"ES HF_depr\",\"ES HF_LF\",\n",
    "                  \"p adj H_depr\", \"p adj H_LF\", \"p adj H_HF\",\"p adj LF_depr\", \"p adj HF_depr\", \"p adj HF_LF\"]\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "initial-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "#left right asymmetry \n",
    "#right frontal alfa \n",
    "\n",
    "as_depr = alpha_left_depr / alpha_right_depr\n",
    "as_health = alpha_left / alpha_right\n",
    "as_LF = alpha_left_LF / alpha_right_LF\n",
    "as_HF = alpha_left_HF / alpha_right_HF\n",
    "\n",
    "for i in range(5):\n",
    "    #first: compare all lowest frequencies \n",
    "    #4 means, 4 sd's, 6p-values, 6EFs, 6 corrected p-values\n",
    "    \n",
    "    health = as_health[:,i]\n",
    "    depr = as_depr[:,i]\n",
    "    LF = as_LF[:,i]\n",
    "    HF = as_HF[:,i]\n",
    "\n",
    "    array = numpy.zeros(shape = (1, 20))\n",
    "\n",
    "    array[0][0] = mean(health)\n",
    "    array[0][1] = mean(depr)\n",
    "    array[0][2] = mean(LF)\n",
    "    array[0][3] = mean(HF)\n",
    "    array[0][4] = np.std(health)\n",
    "    array[0][5] = np.std(depr)\n",
    "    array[0][6] = np.std(LF)\n",
    "    array[0][7] = np.std(HF)\n",
    "    array[0][8] = stats.ttest_ind(health, depr).pvalue\n",
    "    array[0][9] = stats.ttest_ind(health, LF).pvalue\n",
    "    array[0][10] = stats.ttest_ind(health, HF).pvalue\n",
    "    array[0][11] = stats.ttest_ind(LF, depr).pvalue\n",
    "    array[0][12] = stats.ttest_ind(HF, depr).pvalue\n",
    "    array[0][13] = stats.ttest_ind(HF, LF).pvalue\n",
    "    array[0][14] = EFsize(health, depr)\n",
    "    array[0][15] = EFsize(health, LF)\n",
    "    array[0][16] = EFsize(health, HF)\n",
    "    array[0][17] = EFsize(LF, depr)\n",
    "    array[0][18] = EFsize(HF, depr)\n",
    "    array[0][19] = EFsize(HF, LF)\n",
    "\n",
    "    #make new array with adjusted p-values!\n",
    "    if i == 0:\n",
    "        array0 = array\n",
    "    elif i ==1:\n",
    "        array1 = array\n",
    "    elif i == 2:\n",
    "        array2 = array\n",
    "    elif i == 3:\n",
    "        array3 = array\n",
    "    else:\n",
    "        array4 = array\n",
    "\n",
    "tuple = (array0, array1, array2, array3, array4)\n",
    "total = np.vstack(tuple)\n",
    "\n",
    "parray = total[:, [8,9,10,11,12,13]]\n",
    "\n",
    "padj = np.copy(parray)\n",
    "\n",
    "padj[:,0] = statsx.p_adjust(FloatVector(parray[:,0]), method = 'holm')\n",
    "padj[:,1] = statsx.p_adjust(FloatVector(parray[:,1]), method = 'holm')\n",
    "padj[:,2] = statsx.p_adjust(FloatVector(parray[:,2]), method = 'holm')\n",
    "padj[:,3] = statsx.p_adjust(FloatVector(parray[:,3]), method = 'holm')\n",
    "padj[:,4] = statsx.p_adjust(FloatVector(parray[:,4]), method = 'holm')\n",
    "padj[:,5] = statsx.p_adjust(FloatVector(parray[:,5]), method = 'holm')\n",
    "\n",
    "tuplex = (total, padj)\n",
    "total_adj = np.column_stack(tuplex)\n",
    "\n",
    "file_name = mydir + \"/L_F_asymmetry frontal alfa p-values.csv\"\n",
    "outcome = pd.DataFrame.from_records(total_adj)\n",
    "outcome.columns = [\"mean health\",\"mean depr\",\"meanLF\", \"meanHF\", \"std health\",\"std depr\",\"std LF\",\"std HF\",\"p H_D\",\"p H_LF\",\n",
    "                  \"p H_HF\",\"p LF_depr\",\"p HF_depr\",\"p HF_LF\",\"ES H_HF\", \"ES H_LF\",\"ES H_HF\",\"ES LF_depr\",\"ES HF_depr\",\"ES HF_LF\",\n",
    "                  \"p adj H_depr\", \"p adj H_LF\", \"p adj H_HF\",\"p adj LF_depr\", \"p adj HF_depr\", \"p adj HF_LF\"]\n",
    "outcome.to_csv(path_or_buf = file_name, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-leeds",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "thesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
